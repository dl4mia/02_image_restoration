{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from tifffile import imread\n",
    "from csbdeep.utils import axes_dict, plot_some, plot_history\n",
    "from csbdeep.utils.tf import limit_gpu_memory\n",
    "from csbdeep.io import load_training_data\n",
    "from csbdeep.models import Config, CARE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TensorFlow backend uses all available GPU memory by default, hence it can be useful to limit it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit_gpu_memory(fraction=1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Training data\n",
    "\n",
    "Load training data generated via [1_datagen.ipynb](1_datagen.ipynb), use 10% as validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X,Y), (X_val,Y_val), axes = load_training_data('data/my_SEM_training_data.npz', validation_split=0.1, verbose=True)\n",
    "\n",
    "c = axes_dict(axes)['C']\n",
    "n_channel_in, n_channel_out = X.shape[c], Y.shape[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plot_some(X_val[:5],Y_val[:5])\n",
    "plt.suptitle('5 example validation patches (top row: source, bottom row: target)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# CARE model\n",
    "\n",
    "Before we construct the actual CARE model, we have to define its configuration via a `Config` object, which includes \n",
    "* parameters of the underlying neural network,\n",
    "* the learning rate,\n",
    "* the number of parameter updates per epoch,\n",
    "* the loss function, and\n",
    "* whether the model is probabilistic or not.\n",
    "\n",
    "The defaults should be sensible in many cases, so a change should only be necessary if the training process fails.  \n",
    "\n",
    "---\n",
    "\n",
    "<span style=\"color:red;font-weight:bold;\">Important</span>: Note that for this notebook we use a very small number of update steps per epoch for immediate feedback, whereas this number should be increased considerably (e.g. `train_steps_per_epoch=400`) to obtain a well-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(axes='YXC', \n",
    "                n_channel_in=1, \n",
    "                n_channel_out=1, \n",
    "                train_steps_per_epoch=3,\n",
    "                train_epochs=10,\n",
    "                unet_n_depth=2,\n",
    "                unet_kern_size=3,\n",
    "                train_batch_size=16,\n",
    "                train_loss='mae')\n",
    "print(config)\n",
    "vars(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a CARE model with the chosen configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CARE(config, 'my_SEM_model', basedir='models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Training\n",
    "\n",
    "Training the model will likely take some time. We recommend to monitor the progress with [TensorBoard](https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard) (example below), which allows you to inspect the losses during training.\n",
    "Furthermore, you can look at the predictions for some of the validation images, which can be helpful to recognize problems early on.\n",
    "\n",
    "You can start TensorBoard from the current working directory with `tensorboard --logdir=.`\n",
    "Then connect to [http://localhost:6006/](http://localhost:6006/) with your browser.\n",
    "\n",
    "![](http://csbdeep.bioimagecomputing.com/img/tensorboard_denoising3D.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.train(X,Y, validation_data=(X_val,Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "history = model.train(X,Y, validation_data=(X_val,Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot final training history (available in TensorBoard during training):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(sorted(list(history.history.keys())))\n",
    "plt.figure(figsize=(16,5))\n",
    "plot_history(history,['loss','val_loss'],['mse','val_mse','mae','val_mae']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "Example results for validation images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "_P = model.keras_model.predict(X_val[:5])\n",
    "if config.probabilistic:\n",
    "    _P = _P[...,:(_P.shape[-1]//2)]\n",
    "plot_some(X_val[:5],Y_val[:5],_P,pmax=99.5)\n",
    "plt.suptitle('5 example validation patches\\n'      \n",
    "             'top row: input (source),  '          \n",
    "             'middle row: target (ground truth),  '\n",
    "             'bottom row: predicted from source');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Export model to be used with CSBDeep **Fiji** plugins and **KNIME** workflows\n",
    "\n",
    "See https://github.com/CSBDeep/CSBDeep_website/wiki/Your-Model-in-Fiji for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export_TF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
